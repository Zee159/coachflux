# Claude Sonnet 3.7 Setup Guide

## ‚úÖ Updated to Claude Sonnet 4 (20250514)

The project has been configured to use **Claude Sonnet 4** (latest version) instead of OpenAI.

---

## üîß Changes Made

### 1. Dependencies Updated
- ‚ùå Removed: `openai` package
- ‚úÖ Added: `@anthropic-ai/sdk` package

### 2. Coach.ts Updated
- Model: `claude-sonnet-4-20250514` (Sonnet 3.7 successor)
- Temperature: `0` (deterministic)
- Max tokens: 600 for primary, 300 for validator
- System prompts enhanced with JSON-only instructions

### 3. Environment Variable
- Changed from: `OPENAI_API_KEY`
- Changed to: `ANTHROPIC_API_KEY`

---

## üöÄ Setup Instructions

### Step 1: Start Convex Backend

```bash
pnpm convex:dev
```

This will:
- Initialize Convex
- Open the Convex dashboard in your browser
- Create `.env.local` with your deployment URL

### Step 2: Set API Key in Convex Dashboard

Once the dashboard opens:

1. Go to **Settings** ‚Üí **Environment Variables**
2. Click **Add Variable**
3. Enter:
   - **Key**: `ANTHROPIC_API_KEY`
   - **Value**: `sk-ant-api03-YOUR_API_KEY_HERE` (get from https://console.anthropic.com)
4. Click **Save**

### Step 3: Start Frontend

In a new terminal:

```bash
pnpm dev
```

Visit: `http://localhost:3000`

---

## üéØ Claude Sonnet 4 Features

### Why Claude Sonnet 4?
- **Latest model** (released May 2025)
- **Better reasoning** than GPT-4o-mini
- **Strong JSON adherence** - Excellent at structured outputs
- **Lower hallucination** - More factual and grounded
- **Cost-effective** - Competitive pricing with GPT-4o-mini
- **Excellent safety** - Built-in safety features

### Model Specs
- **Name**: `claude-sonnet-4-20250514`
- **Context**: 200k tokens
- **Output**: Up to 8k tokens (we use 600 max)
- **Temperature**: 0 (deterministic)
- **Pricing**: ~$3 per million input tokens, ~$15 per million output tokens

### JSON Mode
Unlike OpenAI's native JSON mode, Claude uses instruction-based JSON output:
- System prompt explicitly states "respond with ONLY valid JSON"
- User prompt reinforces JSON-only requirement
- Works reliably with temperature 0

---

## üîÑ Migration Notes

### API Differences

**OpenAI (Before):**
```typescript
const response = await client.chat.completions.create({
  model: "gpt-4o-mini",
  temperature: 0,
  response_format: { type: "json_object" },
  messages: [
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt }
  ]
});
const text = response.choices[0].message?.content;
```

**Anthropic (Now):**
```typescript
const response = await client.messages.create({
  model: "claude-sonnet-4-20250514",
  temperature: 0,
  system: systemPrompt + "\n\nYou MUST respond with valid JSON only.",
  messages: [
    { role: "user", content: userPrompt }
  ]
});
const text = response.content[0].type === "text" ? response.content[0].text : "{}";
```

### Key Changes
1. **Response format**: `messages.create()` instead of `chat.completions.create()`
2. **System prompt**: Separate `system` parameter (not in messages array)
3. **Content extraction**: `content[0].text` instead of `choices[0].message.content`
4. **JSON mode**: Instruction-based instead of native `response_format`

---

## üß™ Testing

### Test Primary Call
```bash
# In Convex dashboard Functions tab
# Run: coach:nextStep
{
  "orgId": "...",
  "userId": "...",
  "sessionId": "...",
  "stepName": "goal",
  "userTurn": "I want to improve team communication"
}
```

Expected: Valid JSON response matching GROW schema

### Test Validator
Should reject banned terms:
- "I need therapy for stress" ‚ùå
- "Can you diagnose my problem?" ‚ùå
- "Give me financial advice" ‚ùå

---

## üìä Performance Comparison

| Metric | OpenAI GPT-4o-mini | Claude Sonnet 4 |
|--------|-------------------|-----------------|
| **Response Quality** | Good | Excellent |
| **JSON Adherence** | Native support | Instruction-based (very reliable) |
| **Reasoning** | Good | Better |
| **Safety** | Good | Excellent |
| **Speed** | ~2-3s | ~2-4s |
| **Cost** | ~$0.15/1M tokens in, $0.60/1M out | ~$3/1M in, $15/1M out |
| **Context Window** | 128k | 200k |

---

## üõ°Ô∏è Safety Features

Claude Sonnet 4 includes:
- **Constitutional AI** - Built-in ethical guidelines
- **Harmlessness training** - Reduces harmful outputs
- **Better refusals** - Politely declines inappropriate requests
- **Reduced bias** - More balanced and fair responses

Perfect for our use case where safety is critical!

---

## üîç Troubleshooting

### Error: "ANTHROPIC_API_KEY not configured"
- Ensure you set the environment variable in Convex dashboard
- Wait 5-10 seconds after saving for deployment to update
- Refresh browser if needed

### Error: "Invalid JSON response"
- Claude is highly reliable with temperature 0
- Check that system/user prompts emphasize JSON-only output
- Review raw response in safety incidents table

### API Rate Limits
Claude Sonnet 4 limits:
- **Default**: 50 requests/min, 500K tokens/min
- **Tier 2**: Higher limits after usage
- Implement exponential backoff if needed

---

## üí∞ Cost Estimation

**Per Session (GROW flow):**
- 5 steps √ó 2 calls (primary + validator) = 10 API calls
- Average: ~300 tokens input + ~200 tokens output per call
- Total: ~3000 input + ~2000 output tokens
- Cost: $0.009 input + $0.030 output = **~$0.04 per session**

**Monthly (100 users, 2 sessions/user):**
- 200 sessions √ó $0.04 = **~$8/month**

Very affordable for B2B SaaS!

---

## üìö Resources

- [Anthropic API Docs](https://docs.anthropic.com/)
- [Claude Sonnet Models](https://docs.anthropic.com/claude/docs/models-overview)
- [Prompt Engineering Guide](https://docs.anthropic.com/claude/docs/prompt-engineering)
- [TypeScript SDK](https://github.com/anthropics/anthropic-sdk-typescript)

---

## ‚úÖ Next Steps

1. ‚úÖ Dependencies updated
2. ‚úÖ Code migrated to Anthropic SDK
3. ‚è≥ Set `ANTHROPIC_API_KEY` in Convex dashboard
4. ‚è≥ Test GROW flow end-to-end
5. ‚è≥ Verify safety incident logging
6. ‚è≥ Deploy to production

**Your CoachFlux MVP is now powered by Claude Sonnet 4!** üöÄ
